"""streamlit_rag_ui_refined.py â€“ Refined Modern RAG System
========================================================
æ´—ç·´ã•ã‚ŒãŸãƒ¢ãƒ€ãƒ³ãªRAGã‚·ã‚¹ãƒ†ãƒ UI - å®Ÿç”¨æ€§ã¨ã‚¹ã‚¿ã‚¤ãƒ«ã®èåˆ

èµ·å‹•: streamlit run streamlit_rag_ui_refined.py
"""
from __future__ import annotations

import os
import json
import tempfile
import time
from pathlib import Path
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta

import streamlit as st
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
import pandas as pd

# Plotlyã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    import plotly.graph_objects as go
    import plotly.express as px
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

# â”€â”€ Environment & Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
ENV_DEFAULTS = {
    "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY", ""),
    "EMBEDDING_MODEL": os.getenv("EMBEDDING_MODEL", "text-embedding-ada-002"),
    "LLM_MODEL": os.getenv("LLM_MODEL", "gpt-4o"),
    "COLLECTION_NAME": os.getenv("COLLECTION_NAME", "documents"), 
    "FINAL_K": int(os.getenv("FINAL_K", 5)),
}

# â”€â”€ RAG System Import â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from rag_system import Config, RAGSystem 
except ModuleNotFoundError:
    st.error("âŒ rag_system.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# â”€â”€ Page Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="RAG System â€¢ Document Intelligence",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# â”€â”€ Refined CSS Design â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    :root {
        /* ãƒ€ãƒ¼ã‚¯ãƒ†ãƒ¼ãƒã‚«ãƒ©ãƒ¼ï¼ˆè¦–èªæ€§æ”¹å–„ï¼‰ */
        --bg-primary: #0a0a0a;
        --bg-secondary: #141414;
        --bg-tertiary: #1a1a1a;
        --surface: #242424;
        --surface-hover: #2a2a2a;
        --border: #333333;
        
        /* ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ¼ï¼ˆã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆæ”¹å–„ï¼‰ */
        --text-primary: #ffffff;
        --text-secondary: #b3b3b3;
        --text-tertiary: #808080;
        
        /* ã‚¢ã‚¯ã‚»ãƒ³ãƒˆã‚«ãƒ©ãƒ¼ */
        --accent: #7c3aed;
        --accent-hover: #8b5cf6;
        --accent-light: rgba(124, 58, 237, 0.15);
        
        /* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚«ãƒ©ãƒ¼ */
        --success: #10b981;
        --error: #ef4444;
        --warning: #f59e0b;
        --info: #3b82f6;
    }

    * {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    }

    .stApp {
        background: var(--bg-primary);
        color: var(--text-primary);
    }

    /* Streamlitã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¦ç´ ã‚’éè¡¨ç¤º */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}

    /* ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒãƒ¼ */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }

    ::-webkit-scrollbar-track {
        background: var(--bg-secondary);
    }

    ::-webkit-scrollbar-thumb {
        background: #555;
        border-radius: 4px;
    }

    ::-webkit-scrollbar-thumb:hover {
        background: #666;
    }

    /* ãƒ˜ãƒƒãƒ€ãƒ¼ */
    .main-header {
        background: linear-gradient(135deg, var(--accent) 0%, #a855f7 100%);
        padding: 2rem 3rem;
        border-radius: 16px;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(124, 58, 237, 0.3);
    }

    .header-title {
        font-size: 2.5rem;
        font-weight: 700;
        margin: 0;
        letter-spacing: -1px;
    }

    .header-subtitle {
        font-size: 1.1rem;
        opacity: 0.9;
        margin-top: 0.5rem;
    }

    /* ã‚«ãƒ¼ãƒ‰ */
    .card {
        background: var(--surface);
        border: 1px solid var(--border);
        border-radius: 12px;
        padding: 1.5rem;
        margin-bottom: 1rem;
    }

    /* ãƒãƒ£ãƒƒãƒˆã‚³ãƒ³ãƒ†ãƒŠ - é«˜ã•ã‚’å‰Šé™¤ã—ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«å¿œã˜ã¦ä¼¸ç¸® */
    .chat-container {
        background: var(--bg-secondary);
        border-radius: 16px;
        padding: 1.5rem;
        overflow-y: auto;
        border: 1px solid var(--border);
        max-height: 600px;
    }

    /* ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    .message {
        margin-bottom: 1rem;
        display: flex;
    }

    .user-message {
        margin-left: auto;
        max-width: 70%;
    }

    .ai-message {
        margin-right: auto;
        max-width: 70%;
    }

    .message-bubble {
        padding: 1rem 1.25rem;
        border-radius: 16px;
        word-wrap: break-word;
    }

    .user-bubble {
        background: var(--accent);
        color: white;
        border-bottom-right-radius: 4px;
    }

    .ai-bubble {
        background: var(--surface);
        color: var(--text-primary);
        border: 1px solid var(--border);
        border-bottom-left-radius: 4px;
    }

    /* ã‚½ãƒ¼ã‚¹ã‚«ãƒ¼ãƒ‰ */
    .source-container {
        background: var(--bg-secondary);
        border-radius: 12px;
        padding: 1.5rem;
        border: 1px solid var(--border);
        height: 500px;
        overflow-y: auto;
    }

    .source-item {
        background: var(--surface);
        border-radius: 8px;
        padding: 1rem;
        margin-bottom: 0.75rem;
        border-left: 3px solid var(--accent);
        cursor: pointer;
        transition: all 0.2s ease;
    }

    .source-item:hover {
        transform: translateX(4px);
        background: var(--surface-hover);
    }

    .source-title {
        font-weight: 600;
        color: var(--text-primary);
        margin-bottom: 0.5rem;
    }

    .source-excerpt {
        font-size: 0.875rem;
        color: var(--text-secondary);
        line-height: 1.5;
    }

    /* å…¨æ–‡è¡¨ç¤ºã‚¨ãƒªã‚¢ */
    .full-text-container {
        background: var(--surface);
        border: 1px solid var(--border);
        border-radius: 8px;
        padding: 1rem;
        max-height: 300px;
        overflow-y: auto;
        margin-top: 0.5rem;
        font-size: 0.875rem;
        line-height: 1.6;
        color: var(--text-primary);
    }

    /* çµ±è¨ˆã‚«ãƒ¼ãƒ‰ */
    .stat-card {
        background: var(--surface);
        border: 1px solid var(--border);
        border-radius: 12px;
        padding: 1.5rem;
        text-align: center;
        transition: transform 0.2s ease;
    }

    .stat-card:hover {
        transform: translateY(-2px);
    }

    .stat-number {
        font-size: 2rem;
        font-weight: 700;
        color: var(--accent);
    }

    .stat-label {
        color: var(--text-secondary);
        font-size: 0.875rem;
        text-transform: uppercase;
        letter-spacing: 0.5px;
        margin-top: 0.5rem;
    }

    /* ãƒœã‚¿ãƒ³ */
    .stButton > button {
        background: var(--accent);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.75rem 1.5rem;
        font-weight: 500;
        transition: all 0.2s ease;
    }

    .stButton > button:hover {
        background: var(--accent-hover);
        transform: translateY(-1px);
    }

    /* å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ */
    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea {
        background: var(--surface);
        border: 1px solid var(--border);
        color: var(--text-primary);
        border-radius: 8px;
    }

    .stTextInput > div > div > input:focus,
    .stTextArea > div > div > textarea:focus {
        border-color: var(--accent);
        box-shadow: 0 0 0 2px var(--accent-light);
    }

    /* ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ */
    .stSelectbox > div > div > div {
        background: var(--surface);
        border: 1px solid var(--border);
        color: var(--text-primary);
    }

    /* ã‚¿ãƒ– */
    .stTabs [data-baseweb="tab-list"] {
        background: transparent;
        gap: 0.5rem;
    }

    .stTabs [data-baseweb="tab"] {
        background: var(--surface);
        color: var(--text-secondary);
        border: 1px solid var(--border);
        border-radius: 8px;
        padding: 0.75rem 1.5rem;
        font-weight: 500;
    }

    .stTabs [aria-selected="true"] {
        background: var(--accent);
        color: white;
        border-color: var(--accent);
    }

    /* ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ */
    .stFileUploader > div {
        background: var(--surface);
        border: 2px dashed var(--border);
        border-radius: 12px;
    }

    .stFileUploader > div:hover {
        border-color: var(--accent);
        background: var(--surface-hover);
    }

    /* ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ */
    .stProgress > div > div > div > div {
        background: var(--accent);
    }

    /* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ */
    div[data-testid="metric-container"] {
        background: var(--surface);
        border: 1px solid var(--border);
        border-radius: 8px;
        padding: 1rem;
    }

    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ */
    .css-1d391kg {
        background: var(--bg-secondary);
    }

    /* ãƒ•ã‚©ãƒ¼ãƒ ãƒ©ãƒ™ãƒ« */
    .stFormLabel {
        color: var(--text-primary) !important;
        font-weight: 500;
    }

    /* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ */
    .stSlider > div > div > div > div {
        background: var(--accent);
    }

    /* ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ»ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ */
    .stCheckbox > label > span,
    .stRadio > div > label > span {
        color: var(--text-primary);
    }

    /* æƒ…å ±ãƒœãƒƒã‚¯ã‚¹ */
    .stAlert {
        background: var(--surface);
        color: var(--text-primary);
        border: 1px solid var(--border);
    }
</style>
""", unsafe_allow_html=True)

# â”€â”€ Helper Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _persist_uploaded_file(uploaded_file) -> Path:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€æ™‚ä¿å­˜"""
    if uploaded_file is None:
        raise ValueError("Uploaded file cannot be None")
    tmp_dir = Path(tempfile.gettempdir()) / "rag_uploads"
    tmp_dir.mkdir(exist_ok=True)
    tmp_path = tmp_dir / uploaded_file.name
    tmp_path.write_bytes(uploaded_file.getbuffer())
    return tmp_path

@st.cache_resource(show_spinner=False)
def initialize_rag_system(config: Config) -> RAGSystem:
    """RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
    return RAGSystem(config)

def get_collection_statistics(rag: RAGSystem) -> Dict[str, Any]:
    """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±è¨ˆã®å–å¾—"""
    if not rag:
        return {"documents": 0, "chunks": 0, "collection_name": "N/A"}
    
    try:
        engine = create_engine(rag.connection_string)
        with engine.connect() as conn:
            query = text("""
                SELECT COUNT(DISTINCT document_id) AS num_documents,
                       COUNT(*) AS num_chunks
                FROM document_chunks
                WHERE collection_name = :collection
            """)
            result = conn.execute(query, {"collection": rag.config.collection_name}).first()
            
            return {
                "documents": result.num_documents if result else 0,
                "chunks": result.num_chunks if result else 0,
                "collection_name": rag.config.collection_name
            }
    except Exception as e:
        st.error(f"çµ±è¨ˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—: {e}")
        return {"documents": 0, "chunks": 0, "collection_name": rag.config.collection_name}

def get_documents_dataframe(rag: RAGSystem) -> pd.DataFrame:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§ã®å–å¾—"""
    if not rag:
        return pd.DataFrame()
    
    try:
        engine = create_engine(rag.connection_string)
        with engine.connect() as conn:
            query = text("""
                SELECT document_id, COUNT(*) as chunk_count, MAX(created_at) as last_updated
                FROM document_chunks
                WHERE collection_name = :collection
                GROUP BY document_id
                ORDER BY last_updated DESC
            """)
            result = conn.execute(query, {"collection": rag.config.collection_name})
            df = pd.DataFrame(result.fetchall(), columns=["Document ID", "Chunks", "Last Updated"])
            if not df.empty and "Last Updated" in df.columns:
                df["Last Updated"] = pd.to_datetime(df["Last Updated"]).dt.strftime("%Y-%m-%d %H:%M")
            return df
    except Exception:
        return pd.DataFrame()

def get_query_history_data(days: int = 30) -> pd.DataFrame:
    """ã‚¯ã‚¨ãƒªå±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰"""
    import numpy as np
    dates = pd.date_range(end=datetime.now(), periods=days, freq='D')
    queries = [20 + int(10 * abs(np.sin(i/5))) for i in range(days)]
    return pd.DataFrame({'Date': dates, 'Queries': queries})

# â”€â”€ Initialize Session State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_sources" not in st.session_state:
    st.session_state.current_sources = []
if "rag_system" not in st.session_state:
    if ENV_DEFAULTS["OPENAI_API_KEY"]:
        try:
            config = Config()
            st.session_state.rag_system = initialize_rag_system(config)
            st.toast("âœ… ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ", icon="âœ…")
        except Exception as e:
            st.error(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

# â”€â”€ Main Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<div class="main-header">
    <h1 class="header-title">RAG System</h1>
    <p class="header-subtitle">Intelligent Document Analysis & Question Answering</p>
</div>
""", unsafe_allow_html=True)

# â”€â”€ Get RAG System â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
rag = st.session_state.get("rag_system")

# â”€â”€ Sidebar Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.markdown("<h2 style='color: var(--text-primary);'>âš™ï¸ Configuration</h2>", unsafe_allow_html=True)
    
    if rag:
        # System Status
        st.success(f"âœ… System Online - Collection: **{rag.config.collection_name}**")
    
    # Configuration Form
    with st.form("config_form"):
        st.markdown("### ğŸ¤– Model Settings")
        
        embedding_model = st.selectbox(
            "Embedding Model",
            ["text-embedding-ada-002", "text-embedding-3-small", "text-embedding-3-large"],
            index=0 if not rag else (
                0 if rag.config.embedding_model == "text-embedding-ada-002" else
                1 if rag.config.embedding_model == "text-embedding-3-small" else 2
            )
        )
        
        llm_model = st.selectbox(
            "Language Model",
            ["gpt-4o", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo"],
            index=0 if not rag else (
                0 if rag.config.llm_model == "gpt-4o" else
                1 if rag.config.llm_model == "gpt-4-turbo" else
                2 if rag.config.llm_model == "gpt-4" else 3
            )
        )
        
        st.markdown("### ğŸ” Search Settings")
        
        collection_name = st.text_input(
            "Collection Name",
            value=rag.config.collection_name if rag else ENV_DEFAULTS["COLLECTION_NAME"]
        )
        
        final_k = st.slider(
            "æ¤œç´¢çµæœæ•° (Final K)",
            min_value=1,
            max_value=20,
            value=rag.config.final_k if rag else ENV_DEFAULTS["FINAL_K"],
            help="LLMã«æ¸¡ã™æœ€çµ‚çš„ãªãƒãƒ£ãƒ³ã‚¯æ•°"
        )
        
        st.markdown("### ğŸ“Š Chunking Settings")
        
        chunk_size = st.number_input(
            "Chunk Size",
            min_value=100,
            max_value=5000,
            value=int(os.getenv("CHUNK_SIZE", 1000)),
            step=100
        )
        
        chunk_overlap = st.number_input(
            "Chunk Overlap",
            min_value=0,
            max_value=1000,
            value=int(os.getenv("CHUNK_OVERLAP", 200)),
            step=50
        )
        
        apply_button = st.form_submit_button("Apply Settings", use_container_width=True)

# Handle configuration update
if apply_button:
    updated_config = Config(
        openai_api_key=ENV_DEFAULTS["OPENAI_API_KEY"],
        embedding_model=embedding_model,
        llm_model=llm_model,
        collection_name=collection_name,
        final_k=int(final_k),
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        db_host=os.getenv("DB_HOST", "localhost"),
        db_port=os.getenv("DB_PORT", "5432"),
        db_name=os.getenv("DB_NAME", "postgres"),
        db_user=os.getenv("DB_USER", "postgres"),
        db_password=os.getenv("DB_PASSWORD", "your-password"),
    )
    
    try:
        with st.spinner("è¨­å®šã‚’é©ç”¨ã—ã¦ã„ã¾ã™..."):
            if "rag_system" in st.session_state:
                del st.session_state["rag_system"]
            st.session_state["rag_system"] = initialize_rag_system(updated_config)
            rag = st.session_state["rag_system"]
        st.success("âœ… è¨­å®šãŒæ­£å¸¸ã«é©ç”¨ã•ã‚Œã¾ã—ãŸ")
        st.rerun()
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

# â”€â”€ Main Tabs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¬ **Chat**", "ğŸ“Š **Analytics**", "ğŸ“ **Documents**", "âš™ï¸ **Settings**"])

# â”€â”€ Tab 1: Chat Interface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab1:
    if not rag:
        st.info("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ: å…¥åŠ›ã‚¨ãƒªã‚¢ã‚’ä¸Šéƒ¨ã«é…ç½®
        # Input Area
        st.markdown("### ğŸ’¬ è³ªå•ã‚’å…¥åŠ›")
        user_input = st.text_area(
            "è³ªå•ã‚’å…¥åŠ›",
            placeholder="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„...",
            height=80,
            key="user_input",
            label_visibility="collapsed"
        )
        
        col1, col2 = st.columns([4, 1])
        with col1:
            send_button = st.button("é€ä¿¡", type="primary", use_container_width=True)
        with col2:
            clear_button = st.button("ã‚¯ãƒªã‚¢", use_container_width=True)
        
        # Handle send
        if send_button and user_input:
            st.session_state.messages.append({"role": "user", "content": user_input})
            
            with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                try:
                    response = rag.query(user_input)
                    answer = response.get("answer", "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                    
                    st.session_state.messages.append({"role": "assistant", "content": answer})
                    st.session_state.current_sources = response.get("sources", [])
                    
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            
            st.rerun()
        
        # Handle clear
        if clear_button:
            st.session_state.messages = []
            st.session_state.current_sources = []
            st.rerun()
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¨ã‚½ãƒ¼ã‚¹ã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤º
        st.markdown("---")
        chat_col, source_col = st.columns([2, 1])
        
        with chat_col:
            st.markdown("#### ä¼šè©±å±¥æ­´")
            # Chat History
            chat_container = st.container()
            with chat_container:
                if st.session_state.messages:
                    for message in st.session_state.messages:
                        if message["role"] == "user":
                            st.markdown(f"""
                            <div class="message user-message">
                                <div class="message-bubble user-bubble">
                                    {message["content"]}
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.markdown(f"""
                            <div class="message ai-message">
                                <div class="message-bubble ai-bubble">
                                    {message["content"]}
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                else:
                    st.info("ã¾ã ä¼šè©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šã®å…¥åŠ›æ¬„ã‹ã‚‰è³ªå•ã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚")
        
        with source_col:
            st.markdown("#### ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹")
            source_container = st.container()
            with source_container:
                if st.session_state.current_sources:
                    for i, source in enumerate(st.session_state.current_sources):
                        doc_id = source.get('metadata', {}).get('document_id', 'Unknown')
                        chunk_id = source.get('metadata', {}).get('chunk_id', 'N/A')
                        excerpt = source.get('excerpt', '')[:150] + '...' if len(source.get('excerpt', '')) > 150 else source.get('excerpt', '')
                        
                        # ã‚½ãƒ¼ã‚¹ã‚«ãƒ¼ãƒ‰
                        st.markdown(f"""
                        <div class="source-item">
                            <div class="source-title">ã‚½ãƒ¼ã‚¹ {i+1}: {doc_id}</div>
                            <div class="source-excerpt">{excerpt}</div>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # å…¨æ–‡è¡¨ç¤ºãƒœã‚¿ãƒ³
                        if st.button(f"å…¨æ–‡ã‚’è¡¨ç¤º", key=f"show_full_{i}"):
                            st.session_state[f"show_full_text_{i}"] = not st.session_state.get(f"show_full_text_{i}", False)
                        
                        # å…¨æ–‡è¡¨ç¤º
                        if st.session_state.get(f"show_full_text_{i}", False):
                            full_text = source.get('full_content', 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãªã—')
                            st.markdown(f"""
                            <div class="full-text-container">
                                <strong>Chunk ID:</strong> {chunk_id}<br><br>
                                {full_text}
                            </div>
                            """, unsafe_allow_html=True)
                else:
                    st.info("è³ªå•ã‚’é€ä¿¡ã™ã‚‹ã¨ã€å‚ç…§ã—ãŸã‚½ãƒ¼ã‚¹ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™")

# â”€â”€ Tab 2: Analytics Dashboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab2:
    if rag:
        stats = get_collection_statistics(rag)
        
        # Metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown(f"""
            <div class="stat-card">
                <div class="stat-number">{stats['documents']:,}</div>
                <div class="stat-label">Documents</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="stat-card">
                <div class="stat-number">{stats['chunks']:,}</div>
                <div class="stat-label">Total Chunks</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            avg_chunks = stats['chunks'] // max(stats['documents'], 1)
            st.markdown(f"""
            <div class="stat-card">
                <div class="stat-number">{avg_chunks}</div>
                <div class="stat-label">Avg Chunks/Doc</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            query_count = len(st.session_state.messages) // 2
            st.markdown(f"""
            <div class="stat-card">
                <div class="stat-number">{query_count}</div>
                <div class="stat-label">Total Queries</div>
            </div>
            """, unsafe_allow_html=True)
        
        # Query History Chart
        st.markdown("### ğŸ“ˆ è³ªå•æ•°ã®æ¨ç§»ï¼ˆæ—¥åˆ¥ï¼‰")
        st.caption("éå»30æ—¥é–“ã®è³ªå•æ•°ã®æ¨ç§»ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™")
        
        if PLOTLY_AVAILABLE:
            # Plotlyã‚’ä½¿ç”¨
            query_data = get_query_history_data(30)
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=query_data['Date'],
                y=query_data['Queries'],
                mode='lines+markers',
                name='è³ªå•æ•°',
                line=dict(color='#7c3aed', width=3),
                marker=dict(size=8, color='#8b5cf6'),
                fill='tozeroy',
                fillcolor='rgba(124, 58, 237, 0.1)'
            ))
            
            fig.update_layout(
                template="plotly_dark",
                height=400,
                showlegend=False,
                margin=dict(l=0, r=0, t=0, b=0),
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                xaxis=dict(
                    showgrid=False,
                    title="æ—¥ä»˜"
                ),
                yaxis=dict(
                    showgrid=True,
                    gridcolor='rgba(255,255,255,0.1)',
                    title="è³ªå•æ•°"
                ),
                hovermode='x unified'
            )
            
            st.plotly_chart(fig, use_container_width=True)
        else:
            # Streamlitæ¨™æº–ã®ãƒãƒ£ãƒ¼ãƒˆ
            query_data = get_query_history_data(30)
            st.line_chart(query_data.set_index('Date'))
        
        # Recent Activity
        st.markdown("### ğŸ• æœ€è¿‘ã®è³ªå•")
        
        if st.session_state.messages:
            recent_questions = []
            for i, msg in enumerate(st.session_state.messages):
                if msg["role"] == "user":
                    recent_questions.append({
                        "è³ªå•": msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"],
                        "æ™‚åˆ»": (datetime.now() - timedelta(minutes=len(st.session_state.messages)-i)).strftime("%H:%M")
                    })
            
            if recent_questions:
                df_questions = pd.DataFrame(recent_questions[-5:])  # æœ€æ–°5ä»¶
                st.dataframe(df_questions, use_container_width=True, hide_index=True)
            else:
                st.info("ã¾ã è³ªå•ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            st.info("ã¾ã è³ªå•ãŒã‚ã‚Šã¾ã›ã‚“")
    else:
        st.info("ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„")

# â”€â”€ Tab 3: Document Management â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab3:
    if rag:
        st.markdown("### ğŸ“¤ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        
        uploaded_files = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã¾ãŸã¯ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—",
            accept_multiple_files=True,
            type=["pdf", "txt", "md", "docx", "doc"],
            label_visibility="collapsed"
        )
        
        if uploaded_files:
            st.markdown(f"#### é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ« ({len(uploaded_files)})")
            
            # File preview
            file_data = []
            for file in uploaded_files:
                file_data.append({
                    "ãƒ•ã‚¡ã‚¤ãƒ«å": file.name,
                    "ã‚µã‚¤ã‚º": f"{file.size / 1024:.1f} KB",
                    "ã‚¿ã‚¤ãƒ—": file.type or "ä¸æ˜"
                })
            
            st.dataframe(pd.DataFrame(file_data), use_container_width=True, hide_index=True)
            
            # Process button
            if st.button("ğŸš€ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†", type="primary", use_container_width=True):
                progress = st.progress(0)
                status_text = st.empty()
                
                try:
                    paths = []
                    for i, file in enumerate(uploaded_files):
                        status_text.text(f"å‡¦ç†ä¸­: {file.name}")
                        progress.progress((i + 1) / len(uploaded_files))
                        
                        path = _persist_uploaded_file(file)
                        paths.append(str(path))
                    
                    status_text.text("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ä¸­...")
                    rag.ingest_documents(paths)
                    
                    progress.progress(1.0)
                    st.success(f"âœ… {len(uploaded_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã¾ã—ãŸï¼")
                    time.sleep(1)
                    st.balloons()
                    
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                finally:
                    progress.empty()
                    status_text.empty()
        
        # Document List
        st.markdown("### ğŸ“š ç™»éŒ²æ¸ˆã¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
        
        docs_df = get_documents_dataframe(rag)
        if not docs_df.empty:
            st.dataframe(docs_df, use_container_width=True, hide_index=True)
            
            # Delete functionality
            st.markdown("### ğŸ—‘ï¸ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‰Šé™¤")
            
            col1, col2 = st.columns([1, 2])
            with col1:
                doc_to_delete = st.selectbox(
                    "å‰Šé™¤å¯¾è±¡",
                    ["é¸æŠã—ã¦ãã ã•ã„..."] + docs_df["Document ID"].tolist(),
                    label_visibility="collapsed"
                )
            
            with col2:
                if doc_to_delete != "é¸æŠã—ã¦ãã ã•ã„...":
                    if st.button("å‰Šé™¤å®Ÿè¡Œ", type="secondary"):
                        try:
                            with st.spinner(f"å‰Šé™¤ä¸­: {doc_to_delete}"):
                                success, message = rag.delete_document_by_id(doc_to_delete)
                                if success:
                                    st.success(message)
                                    time.sleep(1)
                                    st.rerun()
                                else:
                                    st.error(message)
                        except Exception as e:
                            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.info("ã¾ã ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    else:
        st.info("ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„")

# â”€â”€ Tab 4: Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab4:
    st.markdown("### âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
    st.caption("RAGã‚·ã‚¹ãƒ†ãƒ ã®è©³ç´°ãªè¨­å®šã‚’è¡Œã„ã¾ã™ã€‚å¤‰æ›´å¾Œã¯ã€Œè¨­å®šã‚’é©ç”¨ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
    
    # ç¾åœ¨ã®è¨­å®šå€¤ã‚’å–å¾—
    current_config = {
        "embedding_model": rag.config.embedding_model if rag else ENV_DEFAULTS["EMBEDDING_MODEL"],
        "llm_model": rag.config.llm_model if rag else ENV_DEFAULTS["LLM_MODEL"],
        "collection_name": rag.config.collection_name if rag else ENV_DEFAULTS["COLLECTION_NAME"],
        "final_k": rag.config.final_k if rag else ENV_DEFAULTS["FINAL_K"],
        "chunk_size": rag.config.chunk_size if rag else int(os.getenv("CHUNK_SIZE", 1000)),
        "chunk_overlap": rag.config.chunk_overlap if rag else int(os.getenv("CHUNK_OVERLAP", 200)),
        "vector_search_k": rag.config.vector_search_k if rag else int(os.getenv("VECTOR_SEARCH_K", 10)),
        "keyword_search_k": rag.config.keyword_search_k if rag else int(os.getenv("KEYWORD_SEARCH_K", 10)),
    }
    
    with st.form("detailed_settings_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ¤– AIãƒ¢ãƒ‡ãƒ«è¨­å®š")
            
            # Embedding Model
            embedding_model = st.selectbox(
                "åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«",
                ["text-embedding-ada-002", "text-embedding-3-small", "text-embedding-3-large"],
                index=["text-embedding-ada-002", "text-embedding-3-small", "text-embedding-3-large"].index(current_config["embedding_model"]) if current_config["embedding_model"] in ["text-embedding-ada-002", "text-embedding-3-small", "text-embedding-3-large"] else 0,
                help="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«"
            )
            
            # LLM Model
            llm_model = st.selectbox(
                "è¨€èªãƒ¢ãƒ‡ãƒ«",
                ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo", "gpt-3.5-turbo-16k"],
                index=["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo", "gpt-3.5-turbo-16k"].index(current_config["llm_model"]) if current_config["llm_model"] in ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo", "gpt-3.5-turbo-16k"] else 0,
                help="å›ç­”ç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹GPTãƒ¢ãƒ‡ãƒ«"
            )
            
            st.markdown("#### ğŸ“Š ãƒãƒ£ãƒ³ã‚¯è¨­å®š")
            
            # Chunk Size
            chunk_size = st.number_input(
                "ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º",
                min_value=100,
                max_value=5000,
                value=current_config["chunk_size"],
                step=100,
                help="1ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã®æœ€å¤§æ–‡å­—æ•°"
            )
            
            # Chunk Overlap
            chunk_overlap = st.number_input(
                "ãƒãƒ£ãƒ³ã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—",
                min_value=0,
                max_value=1000,
                value=current_config["chunk_overlap"],
                step=50,
                help="éš£æ¥ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯é–“ã§é‡è¤‡ã™ã‚‹æ–‡å­—æ•°"
            )
        
        with col2:
            st.markdown("#### ğŸ” æ¤œç´¢è¨­å®š")
            
            # Collection Name
            collection_name = st.text_input(
                "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å",
                value=current_config["collection_name"],
                help="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ ¼ç´ã™ã‚‹ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®åå‰"
            )
            
            # Final K
            final_k = st.slider(
                "æœ€çµ‚æ¤œç´¢çµæœæ•° (Final K)",
                min_value=1,
                max_value=20,
                value=current_config["final_k"],
                help="LLMã«æ¸¡ã™æœ€çµ‚çš„ãªãƒãƒ£ãƒ³ã‚¯æ•°"
            )
            
            # Vector Search K
            vector_search_k = st.number_input(
                "ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢æ•° (Vector Search K)",
                min_value=1,
                max_value=50,
                value=current_config["vector_search_k"],
                help="ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§å–å¾—ã™ã‚‹å€™è£œæ•°"
            )
            
            # Keyword Search K
            keyword_search_k = st.number_input(
                "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢æ•° (Keyword Search K)",
                min_value=1,
                max_value=50,
                value=current_config["keyword_search_k"],
                help="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§å–å¾—ã™ã‚‹å€™è£œæ•°"
            )
        
        st.markdown("---")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šï¼ˆå±•é–‹å¯èƒ½ï¼‰
        with st.expander("ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šï¼ˆé«˜åº¦ãªè¨­å®šï¼‰"):
            db_col1, db_col2 = st.columns(2)
            
            with db_col1:
                db_host = st.text_input(
                    "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ›ã‚¹ãƒˆ",
                    value=os.getenv("DB_HOST", "localhost"),
                    help="PostgreSQLã‚µãƒ¼ãƒãƒ¼ã®ãƒ›ã‚¹ãƒˆå"
                )
                
                db_name = st.text_input(
                    "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å",
                    value=os.getenv("DB_NAME", "postgres"),
                    help="ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å"
                )
                
                db_user = st.text_input(
                    "ãƒ¦ãƒ¼ã‚¶ãƒ¼å",
                    value=os.getenv("DB_USER", "postgres"),
                    help="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¦ãƒ¼ã‚¶ãƒ¼å"
                )
            
            with db_col2:
                db_port = st.text_input(
                    "ãƒãƒ¼ãƒˆ",
                    value=os.getenv("DB_PORT", "5432"),
                    help="PostgreSQLã‚µãƒ¼ãƒãƒ¼ã®ãƒãƒ¼ãƒˆç•ªå·"
                )
                
                db_password = st.text_input(
                    "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰",
                    value=os.getenv("DB_PASSWORD", "your-password"),
                    type="password",
                    help="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰"
                )
                
                embedding_dimensions = st.number_input(
                    "åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒæ•°",
                    min_value=384,
                    max_value=3072,
                    value=int(os.getenv("EMBEDDING_DIMENSIONS", 1536)),
                    help="ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®æ¬¡å…ƒæ•°"
                )
        
        # Submit button
        col_submit, col_reset = st.columns([3, 1])
        with col_submit:
            apply_settings = st.form_submit_button("ğŸ”„ è¨­å®šã‚’é©ç”¨", type="primary", use_container_width=True)
        with col_reset:
            reset_settings = st.form_submit_button("â†©ï¸ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True)
    
    # Handle settings update
    if apply_settings:
        try:
            # æ–°ã—ã„è¨­å®šã§ Config ã‚’ä½œæˆ
            updated_config = Config(
                openai_api_key=ENV_DEFAULTS["OPENAI_API_KEY"],
                embedding_model=embedding_model,
                llm_model=llm_model,
                collection_name=collection_name,
                final_k=int(final_k),
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                vector_search_k=vector_search_k,
                keyword_search_k=keyword_search_k,
                db_host=db_host,
                db_port=db_port,
                db_name=db_name,
                db_user=db_user,
                db_password=db_password,
                embedding_dimensions=embedding_dimensions,
                fts_language=os.getenv("FTS_LANGUAGE", "english"),
            )
            
            # è¨­å®šãŒå¤‰æ›´ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
            config_changed = False
            if rag:
                if (updated_config.embedding_model != rag.config.embedding_model or
                    updated_config.llm_model != rag.config.llm_model or
                    updated_config.collection_name != rag.config.collection_name or
                    updated_config.chunk_size != rag.config.chunk_size or
                    updated_config.chunk_overlap != rag.config.chunk_overlap):
                    config_changed = True
            
            if config_changed:
                st.warning("âš ï¸ é‡è¦ãªè¨­å®šãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚’å†åˆæœŸåŒ–ã—ã¾ã™...")
            
            with st.spinner("è¨­å®šã‚’é©ç”¨ã—ã¦ã„ã¾ã™..."):
                if "rag_system" in st.session_state:
                    del st.session_state["rag_system"]
                st.session_state["rag_system"] = initialize_rag_system(updated_config)
                rag = st.session_state["rag_system"]
            
            st.success("âœ… è¨­å®šãŒæ­£å¸¸ã«é©ç”¨ã•ã‚Œã¾ã—ãŸï¼")
            time.sleep(1)
            st.rerun()
            
        except Exception as e:
            st.error(f"âŒ è¨­å®šã®é©ç”¨ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    # Handle reset
    if reset_settings:
        st.info("è¨­å®šã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã™...")
        time.sleep(1)
        st.rerun()
    
    # ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º
    st.markdown("---")
    st.markdown("### ğŸ“‹ ç¾åœ¨ã®è¨­å®š")
    
    if rag:
        config_display = {
            "åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«": rag.config.embedding_model,
            "è¨€èªãƒ¢ãƒ‡ãƒ«": rag.config.llm_model,
            "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å": rag.config.collection_name,
            "ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º": f"{rag.config.chunk_size} æ–‡å­—",
            "ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—": f"{rag.config.chunk_overlap} æ–‡å­—",
            "æœ€çµ‚æ¤œç´¢çµæœæ•°": rag.config.final_k,
            "ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢æ•°": rag.config.vector_search_k,
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢æ•°": rag.config.keyword_search_k,
        }
        
        # 2åˆ—ã§è¡¨ç¤º
        col1, col2 = st.columns(2)
        items = list(config_display.items())
        half = len(items) // 2
        
        with col1:
            for key, value in items[:half]:
                st.markdown(f"**{key}:** {value}")
        
        with col2:
            for key, value in items[half:]:
                st.markdown(f"**{key}:** {value}")
    else:
        st.info("ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")

# â”€â”€ Footer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<div style="margin-top: 3rem; padding: 1.5rem 0; text-align: center; 
            color: var(--text-tertiary); border-top: 1px solid var(--border);">
    <p style="margin: 0;">RAG System â€¢ Built with Streamlit</p>
</div>
""", unsafe_allow_html=True)